<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>WICWIU: WICWIU_src/Optimizer/GradientDescentOptimizer.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(initResizable);
/* @license-end */</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">WICWIU
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('_gradient_descent_optimizer_8hpp_source.html','');});
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">GradientDescentOptimizer.hpp</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="preprocessor">#ifndef GRADIENTDESCENTOPTIMIZER_H_</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="preprocessor">#define GRADIENTDESCENTOPTIMIZER_H_    value</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="preprocessor">#include &quot;../Optimizer.hpp&quot;</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;</div><div class="line"><a name="l00006"></a><span class="lineno"><a class="line" href="class_gradient_descent_optimizer.html">    6</a></span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> DTYPE&gt; <span class="keyword">class </span><a class="code" href="class_gradient_descent_optimizer.html">GradientDescentOptimizer</a> : <span class="keyword">public</span> <a class="code" href="class_optimizer.html">Optimizer</a>&lt;DTYPE&gt;{</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="keyword">private</span>:</div><div class="line"><a name="l00008"></a><span class="lineno"><a class="line" href="class_gradient_descent_optimizer.html#ac1dd9c82ce372c4943ab3651dfb0ab60">    8</a></span>&#160;    <a class="code" href="class_container.html">Container&lt;Operator&lt;DTYPE&gt;</a> *&gt; *<a class="code" href="class_gradient_descent_optimizer.html#ac1dd9c82ce372c4943ab3651dfb0ab60">m_ppParameter</a>;</div><div class="line"><a name="l00010"></a><span class="lineno"><a class="line" href="class_gradient_descent_optimizer.html#aa8097112e0179013915cacbd15593d90">   10</a></span>&#160;    <a class="code" href="class_container.html">Container&lt;Tensor&lt;DTYPE&gt;</a> *&gt; *<a class="code" href="class_gradient_descent_optimizer.html#aa8097112e0179013915cacbd15593d90">m_aaVelocity</a>;</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;</div><div class="line"><a name="l00013"></a><span class="lineno"><a class="line" href="class_gradient_descent_optimizer.html#a91cbb6613c73ef0959975f049b58e7d6">   13</a></span>&#160;    <span class="keywordtype">int</span> <a class="code" href="class_gradient_descent_optimizer.html#a91cbb6613c73ef0959975f049b58e7d6">m_numOfParameter</a>;</div><div class="line"><a name="l00015"></a><span class="lineno"><a class="line" href="class_gradient_descent_optimizer.html#ad0c73577a19af488622794df401da220">   15</a></span>&#160;    <span class="keywordtype">float</span> <a class="code" href="class_gradient_descent_optimizer.html#ad0c73577a19af488622794df401da220">m_momentum</a>;</div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;</div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="keyword">public</span>:</div><div class="line"><a name="l00028"></a><span class="lineno"><a class="line" href="class_gradient_descent_optimizer.html#a0a938de6f183116479a6fd716c52b71f">   28</a></span>&#160;    <a class="code" href="class_gradient_descent_optimizer.html#a0a938de6f183116479a6fd716c52b71f">GradientDescentOptimizer</a>(<a class="code" href="class_container.html">Container</a>&lt;<a class="code" href="class_operator.html">Operator&lt;DTYPE&gt;</a> *&gt; *pParameterContainer, <span class="keywordtype">float</span> pLearningRate, OptimizeDirection pOptimizeDirection) : <a class="code" href="class_optimizer.html">Optimizer</a>&lt;DTYPE&gt;(pParameterContainer, pLearningRate, pOptimizeDirection) {</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="preprocessor">        #ifdef __DEBUG__</span></div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;        std::cout &lt;&lt; <span class="stringliteral">&quot;GradientDescentOptimizer::GradientDescentOptimizer(LossFunction&lt;DTYPE&gt; *, float, OptimizeDirection)&quot;</span> &lt;&lt; <span class="charliteral">&#39;\n&#39;</span>;</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;<span class="preprocessor">        #endif  // __DEBUG__</span></div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;        <a class="code" href="class_gradient_descent_optimizer.html#ac1dd9c82ce372c4943ab3651dfb0ab60">m_ppParameter</a>    = NULL;</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;        <a class="code" href="class_gradient_descent_optimizer.html#aa8097112e0179013915cacbd15593d90">m_aaVelocity</a>     = NULL;</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;        <a class="code" href="class_gradient_descent_optimizer.html#a91cbb6613c73ef0959975f049b58e7d6">m_numOfParameter</a> = 0;</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;        <a class="code" href="class_gradient_descent_optimizer.html#ad0c73577a19af488622794df401da220">m_momentum</a>       = 0.f;</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;        <a class="code" href="class_gradient_descent_optimizer.html#ab968000d204c52e6cb349204ddbc4cd1">Alloc</a>();</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;    }</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;</div><div class="line"><a name="l00050"></a><span class="lineno"><a class="line" href="class_gradient_descent_optimizer.html#ae69269e10e3192374948722698e2b7fe">   50</a></span>&#160;    <a class="code" href="class_gradient_descent_optimizer.html#ae69269e10e3192374948722698e2b7fe">GradientDescentOptimizer</a>(<a class="code" href="class_container.html">Container</a>&lt;<a class="code" href="class_operator.html">Operator&lt;DTYPE&gt;</a> *&gt; *pParameterContainer, <span class="keywordtype">float</span> pLearningRate, <span class="keywordtype">float</span> momentum, OptimizeDirection pOptimizeDirection) : <a class="code" href="class_optimizer.html">Optimizer</a>&lt;DTYPE&gt;(pParameterContainer, pLearningRate, pOptimizeDirection) {</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;<span class="preprocessor">        #ifdef __DEBUG__</span></div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;        std::cout &lt;&lt; <span class="stringliteral">&quot;GradientDescentOptimizer::GradientDescentOptimizer(LossFunction&lt;DTYPE&gt; *, float, OptimizeDirection)&quot;</span> &lt;&lt; <span class="charliteral">&#39;\n&#39;</span>;</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;<span class="preprocessor">        #endif  // __DEBUG__</span></div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;        <a class="code" href="class_gradient_descent_optimizer.html#ac1dd9c82ce372c4943ab3651dfb0ab60">m_ppParameter</a>    = NULL;</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;        <a class="code" href="class_gradient_descent_optimizer.html#aa8097112e0179013915cacbd15593d90">m_aaVelocity</a>     = NULL;</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;        <a class="code" href="class_gradient_descent_optimizer.html#a91cbb6613c73ef0959975f049b58e7d6">m_numOfParameter</a> = 0;</div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;        <a class="code" href="class_gradient_descent_optimizer.html#ad0c73577a19af488622794df401da220">m_momentum</a>       = 0.f;</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;</div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;        <a class="code" href="class_gradient_descent_optimizer.html#ab968000d204c52e6cb349204ddbc4cd1">Alloc</a>(momentum);</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;    }</div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;</div><div class="line"><a name="l00073"></a><span class="lineno"><a class="line" href="class_gradient_descent_optimizer.html#a52d5754cb6ef88880292db9571a673c2">   73</a></span>&#160;    <a class="code" href="class_gradient_descent_optimizer.html#a52d5754cb6ef88880292db9571a673c2">GradientDescentOptimizer</a>(<a class="code" href="class_container.html">Container</a>&lt;<a class="code" href="class_operator.html">Operator&lt;DTYPE&gt;</a> *&gt; *pParameterContainer, <span class="keywordtype">float</span> pLearningRate, <span class="keywordtype">float</span> momentum, <span class="keywordtype">float</span> weightDecayRate, OptimizeDirection pOptimizeDirection) : <a class="code" href="class_optimizer.html">Optimizer</a>&lt;DTYPE&gt;(pParameterContainer, pLearningRate, weightDecayRate, pOptimizeDirection) {</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;<span class="preprocessor">        #ifdef __DEBUG__</span></div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;        std::cout &lt;&lt; <span class="stringliteral">&quot;GradientDescentOptimizer::GradientDescentOptimizer(LossFunction&lt;DTYPE&gt; *, float, OptimizeDirection)&quot;</span> &lt;&lt; <span class="charliteral">&#39;\n&#39;</span>;</div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;<span class="preprocessor">        #endif  // __DEBUG__</span></div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;        <a class="code" href="class_gradient_descent_optimizer.html#ac1dd9c82ce372c4943ab3651dfb0ab60">m_ppParameter</a>    = NULL;</div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;        <a class="code" href="class_gradient_descent_optimizer.html#aa8097112e0179013915cacbd15593d90">m_aaVelocity</a>     = NULL;</div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;        <a class="code" href="class_gradient_descent_optimizer.html#a91cbb6613c73ef0959975f049b58e7d6">m_numOfParameter</a> = 0;</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;        <a class="code" href="class_gradient_descent_optimizer.html#ad0c73577a19af488622794df401da220">m_momentum</a>       = 0.f;</div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;</div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;        <a class="code" href="class_gradient_descent_optimizer.html#ab968000d204c52e6cb349204ddbc4cd1">Alloc</a>(momentum);</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;    }</div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;</div><div class="line"><a name="l00089"></a><span class="lineno"><a class="line" href="class_gradient_descent_optimizer.html#af4344616b07632306e678037ce6c89bb">   89</a></span>&#160;    <a class="code" href="class_gradient_descent_optimizer.html#af4344616b07632306e678037ce6c89bb">~GradientDescentOptimizer</a>() {</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;<span class="preprocessor">        #ifdef __DEBUG__</span></div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;        std::cout &lt;&lt; <span class="stringliteral">&quot;GradientDescentOptimizer::~GradientDescentOptimizer()&quot;</span> &lt;&lt; <span class="charliteral">&#39;\n&#39;</span>;</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;<span class="preprocessor">        #endif  // __DEBUG__</span></div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;        this-&gt;Delete();</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;    }</div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;</div><div class="line"><a name="l00103"></a><span class="lineno"><a class="line" href="class_gradient_descent_optimizer.html#ab968000d204c52e6cb349204ddbc4cd1">  103</a></span>&#160;    <span class="keywordtype">int</span> <a class="code" href="class_gradient_descent_optimizer.html#ab968000d204c52e6cb349204ddbc4cd1">Alloc</a>() {</div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;        <a class="code" href="class_gradient_descent_optimizer.html#ac1dd9c82ce372c4943ab3651dfb0ab60">m_ppParameter</a>    = this-&gt;GetTrainableTensor();</div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;        <a class="code" href="class_gradient_descent_optimizer.html#a91cbb6613c73ef0959975f049b58e7d6">m_numOfParameter</a> = this-&gt;GetTrainableTensorDegree();</div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;        <span class="keywordflow">return</span> TRUE;</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;    }</div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;</div><div class="line"><a name="l00118"></a><span class="lineno"><a class="line" href="class_gradient_descent_optimizer.html#a252fb90356ce7f3bcdd7770d078f2501">  118</a></span>&#160;    <span class="keywordtype">int</span> <a class="code" href="class_gradient_descent_optimizer.html#a252fb90356ce7f3bcdd7770d078f2501">Alloc</a>(<span class="keywordtype">float</span> momentum) {</div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;        <a class="code" href="class_gradient_descent_optimizer.html#ab968000d204c52e6cb349204ddbc4cd1">Alloc</a>();</div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;        <a class="code" href="class_gradient_descent_optimizer.html#aa8097112e0179013915cacbd15593d90">m_aaVelocity</a> = <span class="keyword">new</span> <a class="code" href="class_container.html">Container&lt;Tensor&lt;DTYPE&gt;</a> *&gt;();</div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;</div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;        <a class="code" href="class_shape.html">Shape</a> *pParameterGradShape = NULL;</div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;</div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; <a class="code" href="class_gradient_descent_optimizer.html#a91cbb6613c73ef0959975f049b58e7d6">m_numOfParameter</a>; i++) {</div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;            pParameterGradShape = (*m_ppParameter)[i]-&gt;GetGradient()-&gt;GetShape();</div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;</div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;            <span class="comment">// std::cout &lt;&lt; (*m_ppParameter)[i]-&gt;GetName() &lt;&lt; &#39;\n&#39;;</span></div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;            <span class="comment">// std::cout &lt;&lt; pParameterGradShape &lt;&lt; &#39;\n&#39;;</span></div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;</div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;            <a class="code" href="class_gradient_descent_optimizer.html#aa8097112e0179013915cacbd15593d90">m_aaVelocity</a>-&gt;<a class="code" href="class_container.html#ac875fe061a6d4c1137def5251eaef95a">Push</a>(<span class="keyword">new</span> <a class="code" href="class_tensor.html">Tensor&lt;DTYPE&gt;</a>(<span class="keyword">new</span> <a class="code" href="class_shape.html">Shape</a>(pParameterGradShape)));</div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;            pParameterGradShape = NULL;</div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;        }</div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;</div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;        <a class="code" href="class_gradient_descent_optimizer.html#ad0c73577a19af488622794df401da220">m_momentum</a> = momentum;</div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;</div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;        <span class="keywordflow">return</span> TRUE;</div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;    }</div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;</div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;    <span class="keywordtype">int</span> Delete(){</div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="class_gradient_descent_optimizer.html#aa8097112e0179013915cacbd15593d90">m_aaVelocity</a>) {</div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;            <span class="keyword">delete</span> <a class="code" href="class_gradient_descent_optimizer.html#aa8097112e0179013915cacbd15593d90">m_aaVelocity</a>;</div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;            <a class="code" href="class_gradient_descent_optimizer.html#aa8097112e0179013915cacbd15593d90">m_aaVelocity</a> = NULL;</div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;        }</div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;</div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;        <span class="keywordflow">return</span> TRUE;</div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;    }</div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;</div><div class="line"><a name="l00152"></a><span class="lineno"><a class="line" href="class_gradient_descent_optimizer.html#a3f91a71f3153a5add223200092cced67">  152</a></span>&#160;    <span class="keywordtype">void</span> <a class="code" href="class_gradient_descent_optimizer.html#a3f91a71f3153a5add223200092cced67">InitializeAttributeForGPU</a>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> idOfDevice) {</div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="class_gradient_descent_optimizer.html#ad0c73577a19af488622794df401da220">m_momentum</a> != 0.f) {</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; <a class="code" href="class_gradient_descent_optimizer.html#a91cbb6613c73ef0959975f049b58e7d6">m_numOfParameter</a>; i++) {</div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;                (*m_aaVelocity)[i]-&gt;SetDeviceGPU(idOfDevice);</div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;            }</div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;        }</div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;    }</div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;</div><div class="line"><a name="l00167"></a><span class="lineno"><a class="line" href="class_gradient_descent_optimizer.html#ae6fde8288f07c36b625fb2772a4154d3">  167</a></span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">int</span> <a class="code" href="class_gradient_descent_optimizer.html#ae6fde8288f07c36b625fb2772a4154d3">UpdateParameter</a>() {</div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="class_gradient_descent_optimizer.html#ad0c73577a19af488622794df401da220">m_momentum</a> == 0.f) {</div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; <a class="code" href="class_gradient_descent_optimizer.html#a91cbb6613c73ef0959975f049b58e7d6">m_numOfParameter</a>; i++) {</div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;                <span class="keywordflow">if</span>((*<a class="code" href="class_gradient_descent_optimizer.html#ac1dd9c82ce372c4943ab3651dfb0ab60">m_ppParameter</a>)[i]-&gt;GetIsTrainable()) <a class="code" href="class_gradient_descent_optimizer.html#ae6fde8288f07c36b625fb2772a4154d3">UpdateParameter</a>((*<a class="code" href="class_gradient_descent_optimizer.html#ac1dd9c82ce372c4943ab3651dfb0ab60">m_ppParameter</a>)[i]);</div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;            }</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;        } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; <a class="code" href="class_gradient_descent_optimizer.html#a91cbb6613c73ef0959975f049b58e7d6">m_numOfParameter</a>; i++) {</div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;                <span class="keywordflow">if</span>((*<a class="code" href="class_gradient_descent_optimizer.html#ac1dd9c82ce372c4943ab3651dfb0ab60">m_ppParameter</a>)[i]-&gt;GetIsTrainable()) <a class="code" href="class_gradient_descent_optimizer.html#ae6fde8288f07c36b625fb2772a4154d3">UpdateParameter</a>((*<a class="code" href="class_gradient_descent_optimizer.html#ac1dd9c82ce372c4943ab3651dfb0ab60">m_ppParameter</a>)[i], (*<a class="code" href="class_gradient_descent_optimizer.html#aa8097112e0179013915cacbd15593d90">m_aaVelocity</a>)[i]);</div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;            }</div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;        }</div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;</div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;        <span class="keywordflow">return</span> TRUE;</div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;    }</div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;</div><div class="line"><a name="l00187"></a><span class="lineno"><a class="line" href="class_gradient_descent_optimizer.html#ae9ee1f4f549d532d5011ce6ac6848976">  187</a></span>&#160;    <span class="keywordtype">int</span> <a class="code" href="class_gradient_descent_optimizer.html#ae9ee1f4f549d532d5011ce6ac6848976">UpdateParameter</a>(<a class="code" href="class_operator.html">Operator&lt;DTYPE&gt;</a> *pParameter) {</div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;        <a class="code" href="class_tensor.html">Tensor&lt;DTYPE&gt;</a> *trainable_data = pParameter-&gt;GetResult();</div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;        <a class="code" href="class_tensor.html">Tensor&lt;DTYPE&gt;</a> *gradient       = pParameter-&gt;GetGradient();</div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;</div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;        <span class="keywordtype">float</span> learning_rate   = this-&gt;GetOptimizeDirection() * this-&gt;GetLearningRate();</div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;        <span class="keywordtype">float</span> weightDecayRate = this-&gt;GetWeightDecayRate();</div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;</div><div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;        <span class="keywordtype">int</span> capacity = trainable_data-&gt;<a class="code" href="class_tensor.html#ac9fe35d8f9056cdd8d3a802a85678f4c">GetCapacity</a>();</div><div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;</div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; capacity; i++) {</div><div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;            (*trainable_data)[i] += (learning_rate * (*gradient)[i] + weightDecayRate * (*trainable_data)[i]);</div><div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;        }</div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;</div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;        <span class="keywordflow">return</span> TRUE;</div><div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;    }</div><div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;</div><div class="line"><a name="l00211"></a><span class="lineno"><a class="line" href="class_gradient_descent_optimizer.html#a5f8c15ae8c990f306f36c287f05d258e">  211</a></span>&#160;    <span class="keywordtype">int</span> <a class="code" href="class_gradient_descent_optimizer.html#a5f8c15ae8c990f306f36c287f05d258e">UpdateParameter</a>(<a class="code" href="class_operator.html">Operator&lt;DTYPE&gt;</a> *pParameter, <a class="code" href="class_tensor.html">Tensor&lt;DTYPE&gt;</a> *pVelocity) {</div><div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;        <a class="code" href="class_tensor.html">Tensor&lt;DTYPE&gt;</a> *trainable_data = pParameter-&gt;GetResult();</div><div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;        <a class="code" href="class_tensor.html">Tensor&lt;DTYPE&gt;</a> *gradient       = pParameter-&gt;GetGradient();</div><div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;</div><div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;        <span class="keywordtype">float</span> learning_rate   = this-&gt;GetOptimizeDirection() * this-&gt;GetLearningRate();</div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;        <span class="keywordtype">float</span> weightDecayRate = this-&gt;GetWeightDecayRate();</div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;</div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;        <span class="keywordtype">int</span> capacity = trainable_data-&gt;<a class="code" href="class_tensor.html#ac9fe35d8f9056cdd8d3a802a85678f4c">GetCapacity</a>();</div><div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;</div><div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; capacity; i++) {</div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;            (*pVelocity)[i]      = <a class="code" href="class_gradient_descent_optimizer.html#ad0c73577a19af488622794df401da220">m_momentum</a> * (*pVelocity)[i] + learning_rate * (*gradient)[i];</div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;            (*trainable_data)[i] += ((*pVelocity)[i] + weightDecayRate * (*trainable_data)[i]);</div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;        }</div><div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;</div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;        <span class="keywordflow">return</span> TRUE;</div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;    }</div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;</div><div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;<span class="preprocessor">#ifdef __CUDNN__</span></div><div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;</div><div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;</div><div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;    <span class="keyword">virtual</span> <span class="keywordtype">int</span> UpdateParameterOnGPU() {</div><div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="class_gradient_descent_optimizer.html#ad0c73577a19af488622794df401da220">m_momentum</a> == 0.f) {</div><div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; <a class="code" href="class_gradient_descent_optimizer.html#a91cbb6613c73ef0959975f049b58e7d6">m_numOfParameter</a>; i++) {</div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;                <span class="keywordflow">if</span>((*<a class="code" href="class_gradient_descent_optimizer.html#ac1dd9c82ce372c4943ab3651dfb0ab60">m_ppParameter</a>)[i]-&gt;GetIsTrainable()) UpdateParameterOnGPU((*<a class="code" href="class_gradient_descent_optimizer.html#ac1dd9c82ce372c4943ab3651dfb0ab60">m_ppParameter</a>)[i]);</div><div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;            }</div><div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;        } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; <a class="code" href="class_gradient_descent_optimizer.html#a91cbb6613c73ef0959975f049b58e7d6">m_numOfParameter</a>; i++) {</div><div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;                <span class="keywordflow">if</span>((*<a class="code" href="class_gradient_descent_optimizer.html#ac1dd9c82ce372c4943ab3651dfb0ab60">m_ppParameter</a>)[i]-&gt;GetIsTrainable()) UpdateParameterOnGPU((*<a class="code" href="class_gradient_descent_optimizer.html#ac1dd9c82ce372c4943ab3651dfb0ab60">m_ppParameter</a>)[i], (*<a class="code" href="class_gradient_descent_optimizer.html#aa8097112e0179013915cacbd15593d90">m_aaVelocity</a>)[i]);</div><div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;            }</div><div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;        }</div><div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;</div><div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;        <span class="keywordflow">return</span> TRUE;</div><div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;    }</div><div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;</div><div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;    <span class="keywordtype">int</span> UpdateParameterOnGPU(<a class="code" href="class_operator.html">Operator&lt;DTYPE&gt;</a> *pParameter) {</div><div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;        <a class="code" href="class_tensor.html">Tensor&lt;DTYPE&gt;</a> *trainable_data = pParameter-&gt;GetResult();</div><div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;        <a class="code" href="class_tensor.html">Tensor&lt;DTYPE&gt;</a> *gradient       = pParameter-&gt;GetGradient();</div><div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;</div><div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;        cudnnTensorDescriptor_t dataDesc = trainable_data-&gt;GetDescriptor();</div><div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;        cudnnTensorDescriptor_t gradDesc = gradient-&gt;GetDescriptor();</div><div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;</div><div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;        DTYPE *m_pDevData = trainable_data-&gt;GetGPUData();</div><div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;        DTYPE *m_pDevGrad = gradient-&gt;GetGPUData();</div><div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;</div><div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;        <span class="keywordtype">float</span> learning_rate   = this-&gt;GetOptimizeDirection() * this-&gt;GetLearningRate();</div><div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;        <span class="keywordtype">float</span> weightDecayRate = this-&gt;GetWeightDecayRate();</div><div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;</div><div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;        <span class="keywordtype">float</span> alpha = 1.f + learning_rate * weightDecayRate;</div><div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;        <span class="keywordtype">float</span> beta  = learning_rate;</div><div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;</div><div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;        checkCUDNN(cudnnAddTensor(this-&gt;GetCudnnHandle(),</div><div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;                                  &amp;beta, gradDesc, m_pDevGrad,</div><div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;                                  &amp;alpha, dataDesc, m_pDevData));</div><div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;</div><div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;        <span class="keywordflow">return</span> TRUE;</div><div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;    }</div><div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;</div><div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;    <span class="keywordtype">int</span> UpdateParameterOnGPU(<a class="code" href="class_operator.html">Operator&lt;DTYPE&gt;</a> *pParameter, <a class="code" href="class_tensor.html">Tensor&lt;DTYPE&gt;</a> *pVelocity) {</div><div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;        <a class="code" href="class_tensor.html">Tensor&lt;DTYPE&gt;</a> *trainable_data = pParameter-&gt;GetResult();</div><div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;        <a class="code" href="class_tensor.html">Tensor&lt;DTYPE&gt;</a> *gradient       = pParameter-&gt;GetGradient();</div><div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;</div><div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;        cudnnTensorDescriptor_t dataDesc = trainable_data-&gt;GetDescriptor();</div><div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;        cudnnTensorDescriptor_t gradDesc = gradient-&gt;GetDescriptor();</div><div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;        cudnnTensorDescriptor_t veloDesc = pVelocity-&gt;GetDescriptor();</div><div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;</div><div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;        DTYPE *m_pDevData = trainable_data-&gt;GetGPUData();</div><div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;        DTYPE *m_pDevGrad = gradient-&gt;GetGPUData();</div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;        DTYPE *m_pDevVelo = pVelocity-&gt;GetGPUData();</div><div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;</div><div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;        <span class="keywordtype">float</span> learning_rate   = this-&gt;GetOptimizeDirection() * this-&gt;GetLearningRate();</div><div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;        <span class="keywordtype">float</span> weightDecayRate = this-&gt;GetWeightDecayRate();</div><div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;</div><div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;        <span class="keywordtype">float</span> alpha = 1.f + learning_rate * weightDecayRate;</div><div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;        <span class="comment">// std::cout &lt;&lt; &quot;weight decay  : &quot;&lt;&lt; weightDecayRate &lt;&lt; &#39;\n&#39;;</span></div><div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;        <span class="comment">// std::cout &lt;&lt; &quot;alpha : &quot; &lt;&lt; alpha &lt;&lt; &#39;\n&#39;;</span></div><div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;        <span class="keywordtype">float</span> beta  = learning_rate;</div><div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;</div><div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;        checkCUDNN(cudnnAddTensor(this-&gt;GetCudnnHandle(),</div><div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;                                  &amp;beta, gradDesc, m_pDevGrad,</div><div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;                                  &amp;<a class="code" href="class_gradient_descent_optimizer.html#ad0c73577a19af488622794df401da220">m_momentum</a>, veloDesc, m_pDevVelo));</div><div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;</div><div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;        checkCUDNN(cudnnAddTensor(this-&gt;GetCudnnHandle(),</div><div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;                                  &amp;alpha, veloDesc, m_pDevVelo,</div><div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;                                  &amp;alpha, dataDesc, m_pDevData));</div><div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;</div><div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;        <span class="keywordflow">return</span> TRUE;</div><div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;    }</div><div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;</div><div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;<span class="preprocessor">#endif  // if __CUDNN__</span></div><div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;};</div><div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;</div><div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;</div><div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;<span class="preprocessor">#endif  // GRADIENTDESCENTOPTIMIZER_H_</span></div><div class="ttc" id="class_gradient_descent_optimizer_html_a0a938de6f183116479a6fd716c52b71f"><div class="ttname"><a href="class_gradient_descent_optimizer.html#a0a938de6f183116479a6fd716c52b71f">GradientDescentOptimizer::GradientDescentOptimizer</a></div><div class="ttdeci">GradientDescentOptimizer(Container&lt; Operator&lt; DTYPE &gt; *&gt; *pParameterContainer, float pLearningRate, OptimizeDirection pOptimizeDirection)</div><div class="ttdoc">GradientDescentOptimizer의 생성자. </div><div class="ttdef"><b>Definition:</b> <a href="_gradient_descent_optimizer_8hpp_source.html#l00028">GradientDescentOptimizer.hpp:28</a></div></div>
<div class="ttc" id="class_container_html"><div class="ttname"><a href="class_container.html">Container</a></div><div class="ttdef"><b>Definition:</b> <a href="_container_8hpp_source.html#l00012">Container.hpp:12</a></div></div>
<div class="ttc" id="class_gradient_descent_optimizer_html_a91cbb6613c73ef0959975f049b58e7d6"><div class="ttname"><a href="class_gradient_descent_optimizer.html#a91cbb6613c73ef0959975f049b58e7d6">GradientDescentOptimizer::m_numOfParameter</a></div><div class="ttdeci">int m_numOfParameter</div><div class="ttdoc">업데이트 할 Tensor의 degree </div><div class="ttdef"><b>Definition:</b> <a href="_gradient_descent_optimizer_8hpp_source.html#l00013">GradientDescentOptimizer.hpp:13</a></div></div>
<div class="ttc" id="class_gradient_descent_optimizer_html_a252fb90356ce7f3bcdd7770d078f2501"><div class="ttname"><a href="class_gradient_descent_optimizer.html#a252fb90356ce7f3bcdd7770d078f2501">GradientDescentOptimizer::Alloc</a></div><div class="ttdeci">int Alloc(float momentum)</div><div class="ttdoc">Optimizer의 Alloc 매소드 </div><div class="ttdef"><b>Definition:</b> <a href="_gradient_descent_optimizer_8hpp_source.html#l00118">GradientDescentOptimizer.hpp:118</a></div></div>
<div class="ttc" id="class_gradient_descent_optimizer_html_ab968000d204c52e6cb349204ddbc4cd1"><div class="ttname"><a href="class_gradient_descent_optimizer.html#ab968000d204c52e6cb349204ddbc4cd1">GradientDescentOptimizer::Alloc</a></div><div class="ttdeci">int Alloc()</div><div class="ttdoc">Optimizer의 Alloc 매소드 </div><div class="ttdef"><b>Definition:</b> <a href="_gradient_descent_optimizer_8hpp_source.html#l00103">GradientDescentOptimizer.hpp:103</a></div></div>
<div class="ttc" id="class_optimizer_html"><div class="ttname"><a href="class_optimizer.html">Optimizer</a></div><div class="ttdef"><b>Definition:</b> <a href="_optimizer_8hpp_source.html#l00011">Optimizer.hpp:11</a></div></div>
<div class="ttc" id="class_container_html_ac875fe061a6d4c1137def5251eaef95a"><div class="ttname"><a href="class_container.html#ac875fe061a6d4c1137def5251eaef95a">Container::Push</a></div><div class="ttdeci">int Push(DTYPE pElement)</div><div class="ttdoc">Queue의 push 메소드 </div><div class="ttdef"><b>Definition:</b> <a href="_container_8hpp_source.html#l00051">Container.hpp:51</a></div></div>
<div class="ttc" id="class_tensor_html"><div class="ttname"><a href="class_tensor.html">Tensor</a></div><div class="ttdef"><b>Definition:</b> <a href="_container_8hpp_source.html#l00003">Container.hpp:3</a></div></div>
<div class="ttc" id="class_tensor_html_ac9fe35d8f9056cdd8d3a802a85678f4c"><div class="ttname"><a href="class_tensor.html#ac9fe35d8f9056cdd8d3a802a85678f4c">Tensor::GetCapacity</a></div><div class="ttdeci">int GetCapacity()</div><div class="ttdoc">Tensor의 m_aLongArray의 Capacity를 반환. </div><div class="ttdef"><b>Definition:</b> <a href="_tensor_8hpp_source.html#l00425">Tensor.hpp:425</a></div></div>
<div class="ttc" id="class_gradient_descent_optimizer_html_af4344616b07632306e678037ce6c89bb"><div class="ttname"><a href="class_gradient_descent_optimizer.html#af4344616b07632306e678037ce6c89bb">GradientDescentOptimizer::~GradientDescentOptimizer</a></div><div class="ttdeci">~GradientDescentOptimizer()</div><div class="ttdoc">GradientDescentOptimizer의 소멸자 </div><div class="ttdef"><b>Definition:</b> <a href="_gradient_descent_optimizer_8hpp_source.html#l00089">GradientDescentOptimizer.hpp:89</a></div></div>
<div class="ttc" id="class_shape_html"><div class="ttname"><a href="class_shape.html">Shape</a></div><div class="ttdef"><b>Definition:</b> <a href="_shape_8hpp_source.html#l00014">Shape.hpp:14</a></div></div>
<div class="ttc" id="class_gradient_descent_optimizer_html_ae9ee1f4f549d532d5011ce6ac6848976"><div class="ttname"><a href="class_gradient_descent_optimizer.html#ae9ee1f4f549d532d5011ce6ac6848976">GradientDescentOptimizer::UpdateParameter</a></div><div class="ttdeci">int UpdateParameter(Operator&lt; DTYPE &gt; *pParameter)</div><div class="ttdoc">파라미터 값들을 업데이트 하는 메소드 </div><div class="ttdef"><b>Definition:</b> <a href="_gradient_descent_optimizer_8hpp_source.html#l00187">GradientDescentOptimizer.hpp:187</a></div></div>
<div class="ttc" id="class_gradient_descent_optimizer_html_a3f91a71f3153a5add223200092cced67"><div class="ttname"><a href="class_gradient_descent_optimizer.html#a3f91a71f3153a5add223200092cced67">GradientDescentOptimizer::InitializeAttributeForGPU</a></div><div class="ttdeci">void InitializeAttributeForGPU(unsigned int idOfDevice)</div><div class="ttdoc">m_aaVelocity내부의 Tensor의 device를 idOfDevice번째 GPU로 바꾼다. </div><div class="ttdef"><b>Definition:</b> <a href="_gradient_descent_optimizer_8hpp_source.html#l00152">GradientDescentOptimizer.hpp:152</a></div></div>
<div class="ttc" id="class_gradient_descent_optimizer_html_a5f8c15ae8c990f306f36c287f05d258e"><div class="ttname"><a href="class_gradient_descent_optimizer.html#a5f8c15ae8c990f306f36c287f05d258e">GradientDescentOptimizer::UpdateParameter</a></div><div class="ttdeci">int UpdateParameter(Operator&lt; DTYPE &gt; *pParameter, Tensor&lt; DTYPE &gt; *pVelocity)</div><div class="ttdoc">파라미터 값들을 업데이트 하는 메소드 </div><div class="ttdef"><b>Definition:</b> <a href="_gradient_descent_optimizer_8hpp_source.html#l00211">GradientDescentOptimizer.hpp:211</a></div></div>
<div class="ttc" id="class_gradient_descent_optimizer_html_aa8097112e0179013915cacbd15593d90"><div class="ttname"><a href="class_gradient_descent_optimizer.html#aa8097112e0179013915cacbd15593d90">GradientDescentOptimizer::m_aaVelocity</a></div><div class="ttdeci">Container&lt; Tensor&lt; DTYPE &gt; * &gt; * m_aaVelocity</div><div class="ttdoc">momentum의 누적된 속도 </div><div class="ttdef"><b>Definition:</b> <a href="_gradient_descent_optimizer_8hpp_source.html#l00010">GradientDescentOptimizer.hpp:10</a></div></div>
<div class="ttc" id="class_gradient_descent_optimizer_html_ae69269e10e3192374948722698e2b7fe"><div class="ttname"><a href="class_gradient_descent_optimizer.html#ae69269e10e3192374948722698e2b7fe">GradientDescentOptimizer::GradientDescentOptimizer</a></div><div class="ttdeci">GradientDescentOptimizer(Container&lt; Operator&lt; DTYPE &gt; *&gt; *pParameterContainer, float pLearningRate, float momentum, OptimizeDirection pOptimizeDirection)</div><div class="ttdoc">GradientDescentOptimizer의 생성자. </div><div class="ttdef"><b>Definition:</b> <a href="_gradient_descent_optimizer_8hpp_source.html#l00050">GradientDescentOptimizer.hpp:50</a></div></div>
<div class="ttc" id="class_gradient_descent_optimizer_html_ae6fde8288f07c36b625fb2772a4154d3"><div class="ttname"><a href="class_gradient_descent_optimizer.html#ae6fde8288f07c36b625fb2772a4154d3">GradientDescentOptimizer::UpdateParameter</a></div><div class="ttdeci">virtual int UpdateParameter()</div><div class="ttdoc">파라미터 값들을 업데이트 하는 메소드 </div><div class="ttdef"><b>Definition:</b> <a href="_gradient_descent_optimizer_8hpp_source.html#l00167">GradientDescentOptimizer.hpp:167</a></div></div>
<div class="ttc" id="class_gradient_descent_optimizer_html_ad0c73577a19af488622794df401da220"><div class="ttname"><a href="class_gradient_descent_optimizer.html#ad0c73577a19af488622794df401da220">GradientDescentOptimizer::m_momentum</a></div><div class="ttdeci">float m_momentum</div><div class="ttdoc">Optimizer의 momentum 값 </div><div class="ttdef"><b>Definition:</b> <a href="_gradient_descent_optimizer_8hpp_source.html#l00015">GradientDescentOptimizer.hpp:15</a></div></div>
<div class="ttc" id="class_operator_html"><div class="ttname"><a href="class_operator.html">Operator</a></div><div class="ttdef"><b>Definition:</b> <a href="_container_8hpp_source.html#l00004">Container.hpp:4</a></div></div>
<div class="ttc" id="class_gradient_descent_optimizer_html_a52d5754cb6ef88880292db9571a673c2"><div class="ttname"><a href="class_gradient_descent_optimizer.html#a52d5754cb6ef88880292db9571a673c2">GradientDescentOptimizer::GradientDescentOptimizer</a></div><div class="ttdeci">GradientDescentOptimizer(Container&lt; Operator&lt; DTYPE &gt; *&gt; *pParameterContainer, float pLearningRate, float momentum, float weightDecayRate, OptimizeDirection pOptimizeDirection)</div><div class="ttdoc">GradientDescentOptimizer의 생성자. </div><div class="ttdef"><b>Definition:</b> <a href="_gradient_descent_optimizer_8hpp_source.html#l00073">GradientDescentOptimizer.hpp:73</a></div></div>
<div class="ttc" id="class_gradient_descent_optimizer_html"><div class="ttname"><a href="class_gradient_descent_optimizer.html">GradientDescentOptimizer</a></div><div class="ttdef"><b>Definition:</b> <a href="_gradient_descent_optimizer_8hpp_source.html#l00006">GradientDescentOptimizer.hpp:6</a></div></div>
<div class="ttc" id="class_gradient_descent_optimizer_html_ac1dd9c82ce372c4943ab3651dfb0ab60"><div class="ttname"><a href="class_gradient_descent_optimizer.html#ac1dd9c82ce372c4943ab3651dfb0ab60">GradientDescentOptimizer::m_ppParameter</a></div><div class="ttdeci">Container&lt; Operator&lt; DTYPE &gt; * &gt; * m_ppParameter</div><div class="ttdoc">값을 업데이트 할 Tensor들을 가리키는 포인터 </div><div class="ttdef"><b>Definition:</b> <a href="_gradient_descent_optimizer_8hpp_source.html#l00008">GradientDescentOptimizer.hpp:8</a></div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_d1e2cb908f5411cf8e396afb908a20dd.html">WICWIU_src</a></li><li class="navelem"><a class="el" href="dir_bb6e272ecaeb72399e574062e3c55fe2.html">Optimizer</a></li><li class="navelem"><b>GradientDescentOptimizer.hpp</b></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.14 </li>
  </ul>
</div>
</body>
</html>
